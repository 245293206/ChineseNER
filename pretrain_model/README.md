## 预训练模型

下载预训练模型到当前Folder，受文件大小限制这里移除了checkpoint文件，请自行去以下链接下载完整模型
哈工大wwm bert的vocab文件和google bert一致，所以tokenizer加载哪个模型结果都是一样的。

1. ch_google: Google bert base chinese，L-12_H-768
- 项目链接：https://github.com/google-research/bert
- 模型链接：https://github.com/qiufengyuyi/sequence_tagging/tree/master/bert

2. ch_wwm_ext: 哈工大BERT-wwm-ext, Chinese，ext, L-12_H-768
- 项目链接： https://github.com/ymcui/Chinese-BERT-wwm
- 模型链接：https://drive.google.com/file/d/1buMLEjdtrXE2c4G1rpsNGWEx7lUQ0RHi/view

3. sgns: People's Daily News 人民日报 300d word+Ngram 预训练词向量
- 项目链接：https://github.com/Embedding/Chinese-Word-Vectors
- 模型链接：https://pan.baidu.com/s/1upPkA8KJnxTZBfjuNDtaeQ
